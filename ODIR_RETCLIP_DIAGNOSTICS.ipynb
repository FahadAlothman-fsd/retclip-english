{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ODIR RET-CLIP Pipeline Diagnostics\n",
    "\n",
    "This notebook verifies data quality and identifies potential issues while training runs.\n",
    "\n",
    "**Upload this to Google Colab and run it while training continues in the main notebook.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration - MUST match your training notebook\n",
    "DRIVE_BASE = \"/content/drive/MyDrive/RET-CLIP-ODIR\"\n",
    "DRIVE_DATA = f\"{DRIVE_BASE}/data\"\n",
    "DRIVE_PROMPTS = f\"{DRIVE_BASE}/prompts\"\n",
    "DRIVE_LMDB = f\"{DRIVE_BASE}/lmdb\"\n",
    "\n",
    "print(f\"Base directory: {DRIVE_BASE}\")\n",
    "print(f\"Data directory: {DRIVE_DATA}\")\n",
    "print(f\"Prompts directory: {DRIVE_PROMPTS}\")\n",
    "print(f\"LMDB directory: {DRIVE_LMDB}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function (same as training notebook)\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def get_primary_disease(keywords_str):\n",
    "    \"\"\"Extract first disease from keywords, handling both standard and Chinese commas\"\"\"\n",
    "    if pd.isna(keywords_str):\n",
    "        return \"\"\n",
    "    \n",
    "    # Split on BOTH standard comma (,) AND Chinese comma (Ôºå)\n",
    "    keywords = re.split(r'[,Ôºå]', str(keywords_str))\n",
    "    \n",
    "    # Get first non-empty keyword\n",
    "    for kw in keywords:\n",
    "        kw = kw.strip().lower()\n",
    "        if kw and kw != 'nan':\n",
    "            return kw\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. JSONL eye_side Field Verification ‚≠ê CRITICAL\n",
    "\n",
    "The tripartite loss depends on the `eye_side` field being correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"CHECKING JSONL FORMAT - TRAIN SET\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "with open(f\"{DRIVE_DATA}/train_texts.jsonl\", 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    \n",
    "print(f\"\\nTotal entries: {len(lines)}\")\n",
    "print(f\"Expected: {len(lines) // 3} patients (3 entries each)\\n\")\n",
    "\n",
    "# Check first 3 patients (9 entries)\n",
    "for i in range(min(9, len(lines))):\n",
    "    entry = json.loads(lines[i].strip())\n",
    "    \n",
    "    if i % 3 == 0:\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"Patient: {entry.get('image_ids', ['?'])[0]}\")\n",
    "        print(f\"{'='*80}\")\n",
    "    \n",
    "    print(f\"\\nEntry {i % 3 + 1}/3:\")\n",
    "    print(f\"  text_id: {entry.get('text_id')}\")\n",
    "    print(f\"  eye_side: {entry.get('eye_side', '‚ùå MISSING!')}\")\n",
    "    print(f\"  text: {entry.get('text', '')[:100]}...\")\n",
    "\n",
    "# Verify all entries have eye_side field\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"VALIDATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "missing_eye_side = 0\n",
    "eye_side_counts = {'left': 0, 'right': 0, 'both': 0, 'other': 0}\n",
    "\n",
    "for line in lines:\n",
    "    entry = json.loads(line.strip())\n",
    "    eye_side = entry.get('eye_side')\n",
    "    \n",
    "    if not eye_side:\n",
    "        missing_eye_side += 1\n",
    "    elif eye_side in eye_side_counts:\n",
    "        eye_side_counts[eye_side] += 1\n",
    "    else:\n",
    "        eye_side_counts['other'] += 1\n",
    "\n",
    "if missing_eye_side > 0:\n",
    "    print(f\"\\n‚ùå CRITICAL: {missing_eye_side} entries missing eye_side field!\")\n",
    "else:\n",
    "    print(f\"\\n‚úÖ All {len(lines)} entries have eye_side field\")\n",
    "\n",
    "print(f\"\\nEye side distribution:\")\n",
    "for side, count in eye_side_counts.items():\n",
    "    if count > 0:\n",
    "        print(f\"  {side:10s}: {count:5d} ({count/len(lines)*100:.1f}%)\")\n",
    "\n",
    "expected_each = len(lines) // 3\n",
    "if (eye_side_counts['left'] == expected_each and \n",
    "    eye_side_counts['right'] == expected_each and \n",
    "    eye_side_counts['both'] == expected_each):\n",
    "    print(f\"\\n‚úÖ Perfect balance: {expected_each} entries for each eye_side\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è  Imbalance detected! Expected {expected_each} for each eye_side\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prompt Quality Check\n",
    "\n",
    "Inspect actual prompts to ensure they're clinically meaningful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"PROMPT QUALITY CHECK\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "prompts_df = pd.read_csv(f\"{DRIVE_PROMPTS}/odir_retclip_prompts.csv\")\n",
    "\n",
    "print(f\"\\nTotal patients with prompts: {len(prompts_df)}\")\n",
    "print(f\"Columns: {list(prompts_df.columns)}\")\n",
    "\n",
    "# Sample prompts from different disease categories\n",
    "diseases_to_check = ['normal fundus', 'moderate non proliferative retinopathy', 'glaucoma']\n",
    "\n",
    "for disease in diseases_to_check:\n",
    "    matches = prompts_df[\n",
    "        (prompts_df['left_keywords'].str.contains(disease, na=False, case=False)) |\n",
    "        (prompts_df['right_keywords'].str.contains(disease, na=False, case=False))\n",
    "    ]\n",
    "    \n",
    "    if len(matches) > 0:\n",
    "        sample = matches.iloc[0]\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"Disease: {disease}\")\n",
    "        print(f\"Patient: {sample['patient_id']}, Age: {sample['age']}, Sex: {sample['sex']}\")\n",
    "        print(f\"Left keywords: {sample['left_keywords']}\")\n",
    "        print(f\"Right keywords: {sample['right_keywords']}\")\n",
    "        print(f\"\\nüìù Left eye prompt:\")\n",
    "        print(f\"{sample['prompt_left']}\")\n",
    "        print(f\"\\nüìù Right eye prompt:\")\n",
    "        print(f\"{sample['prompt_right']}\")\n",
    "        print(f\"\\nüìù Patient-level prompt:\")\n",
    "        print(f\"{sample['prompt_patient']}\")\n",
    "    else:\n",
    "        print(f\"\\n‚ö†Ô∏è  No examples found for '{disease}'\")\n",
    "\n",
    "# Check for empty or very short prompts\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"PROMPT LENGTH ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for col in ['prompt_left', 'prompt_right', 'prompt_patient']:\n",
    "    lengths = prompts_df[col].str.len()\n",
    "    print(f\"\\n{col}:\")\n",
    "    print(f\"  Mean: {lengths.mean():.1f} chars\")\n",
    "    print(f\"  Min: {lengths.min()} chars\")\n",
    "    print(f\"  Max: {lengths.max()} chars\")\n",
    "    \n",
    "    very_short = (lengths < 50).sum()\n",
    "    if very_short > 0:\n",
    "        print(f\"  ‚ö†Ô∏è  {very_short} prompts are suspiciously short (<50 chars)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. LMDB Data Integrity\n",
    "\n",
    "Verify LMDB stores the correct data format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install lmdb if needed\n",
    "!pip install -q lmdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lmdb\n",
    "import pickle\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"LMDB INTEGRITY CHECK - PAIRS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "env = lmdb.open(f\"{DRIVE_LMDB}/train/pairs\", readonly=True)\n",
    "with env.begin() as txn:\n",
    "    # Get total samples\n",
    "    num_samples = int(txn.get(b'num_samples').decode('utf-8'))\n",
    "    print(f\"\\nTotal LMDB pairs: {num_samples}\")\n",
    "    \n",
    "    # Expected: 3 texts per patient\n",
    "    train_patients = len(pd.read_csv(f\"{DRIVE_DATA}/train_patients.csv\"))\n",
    "    expected = train_patients * 3\n",
    "    print(f\"Expected pairs: {expected} (3 per patient √ó {train_patients} patients)\")\n",
    "    \n",
    "    if num_samples == expected:\n",
    "        print(f\"‚úÖ LMDB pair count matches expectation\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  Mismatch! Difference: {abs(num_samples - expected)}\")\n",
    "    \n",
    "    # Check first 5 entries\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"SAMPLE ENTRIES\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    for i in range(min(5, num_samples)):\n",
    "        data = txn.get(f\"{i}\".encode('utf-8'))\n",
    "        patient_id, text_id, text = pickle.loads(data)\n",
    "        print(f\"\\nPair {i}:\")\n",
    "        print(f\"  Patient ID: {patient_id}\")\n",
    "        print(f\"  Text ID: {text_id}\")\n",
    "        print(f\"  Text length: {len(text)} chars\")\n",
    "        print(f\"  Text preview: {text[:100]}...\")\n",
    "\n",
    "env.close()\n",
    "\n",
    "# Check images LMDB\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"LMDB INTEGRITY CHECK - IMAGES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "env = lmdb.open(f\"{DRIVE_LMDB}/train/imgs\", readonly=True)\n",
    "with env.begin() as txn:\n",
    "    num_images = int(txn.get(b'num_images').decode('utf-8'))\n",
    "    print(f\"\\nTotal images: {num_images}\")\n",
    "    print(f\"Expected: {train_patients} (one binocular pair per patient)\")\n",
    "    \n",
    "    if num_images == train_patients:\n",
    "        print(f\"‚úÖ LMDB image count matches expectation\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  Mismatch! Difference: {abs(num_images - train_patients)}\")\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Disease Distribution Analysis\n",
    "\n",
    "Check for class imbalance and coverage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"DISEASE DISTRIBUTION ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "train_df = pd.read_csv(f\"{DRIVE_DATA}/train_patients.csv\")\n",
    "test_df = pd.read_csv(f\"{DRIVE_DATA}/test_patients.csv\")\n",
    "\n",
    "# Get primary diseases from train set\n",
    "train_diseases = []\n",
    "for idx, row in train_df.iterrows():\n",
    "    left_kw = get_primary_disease(row['left_keywords'])\n",
    "    right_kw = get_primary_disease(row['right_keywords'])\n",
    "    primary = left_kw if left_kw else right_kw\n",
    "    if primary:\n",
    "        train_diseases.append(primary)\n",
    "\n",
    "# Get primary diseases from test set\n",
    "test_diseases = []\n",
    "for idx, row in test_df.iterrows():\n",
    "    left_kw = get_primary_disease(row['left_keywords'])\n",
    "    right_kw = get_primary_disease(row['right_keywords'])\n",
    "    primary = left_kw if left_kw else right_kw\n",
    "    if primary:\n",
    "        test_diseases.append(primary)\n",
    "\n",
    "train_counts = Counter(train_diseases)\n",
    "test_counts = Counter(test_diseases)\n",
    "\n",
    "print(f\"\\nTraining set: {len(train_diseases)} samples, {len(train_counts)} unique diseases\")\n",
    "print(f\"Test set: {len(test_diseases)} samples, {len(test_counts)} unique diseases\")\n",
    "\n",
    "# Combined disease list\n",
    "all_diseases = sorted(set(train_counts.keys()) | set(test_counts.keys()))\n",
    "\n",
    "print(f\"\\n{'Disease':<45} {'Train':>7} {'Test':>7} {'Total':>7}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for disease in all_diseases:\n",
    "    train_count = train_counts.get(disease, 0)\n",
    "    test_count = test_counts.get(disease, 0)\n",
    "    total = train_count + test_count\n",
    "    \n",
    "    # Flag diseases only in test or only in train\n",
    "    flag = \"\"\n",
    "    if train_count == 0:\n",
    "        flag = \" ‚ö†Ô∏è  TEST ONLY!\"\n",
    "    elif test_count == 0:\n",
    "        flag = \" ‚ÑπÔ∏è  Train only\"\n",
    "    \n",
    "    print(f\"{disease:<45} {train_count:>7} {test_count:>7} {total:>7}{flag}\")\n",
    "\n",
    "# Check for zero-shot issues\n",
    "test_only_diseases = set(test_counts.keys()) - set(train_counts.keys())\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"ZERO-SHOT COVERAGE ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if test_only_diseases:\n",
    "    print(f\"\\n‚ùå CRITICAL: {len(test_only_diseases)} diseases appear ONLY in test set:\")\n",
    "    for disease in sorted(test_only_diseases):\n",
    "        print(f\"  - {disease} ({test_counts[disease]} test samples)\")\n",
    "    print(f\"\\n‚ö†Ô∏è  These diseases will have NO training examples for zero-shot prompts!\")\n",
    "else:\n",
    "    print(f\"\\n‚úÖ All test diseases have training examples\")\n",
    "\n",
    "# Check class imbalance\n",
    "max_train = max(train_counts.values())\n",
    "min_train = min(train_counts.values())\n",
    "imbalance_ratio = max_train / min_train\n",
    "\n",
    "print(f\"\\nClass imbalance:\")\n",
    "print(f\"  Largest class: {max_train} samples\")\n",
    "print(f\"  Smallest class: {min_train} samples\")\n",
    "print(f\"  Imbalance ratio: {imbalance_ratio:.1f}:1\")\n",
    "\n",
    "if imbalance_ratio > 100:\n",
    "    print(f\"  ‚ö†Ô∏è  Severe imbalance! May need class weighting or oversampling.\")\n",
    "elif imbalance_ratio > 10:\n",
    "    print(f\"  ‚ÑπÔ∏è  Moderate imbalance - typical for medical datasets\")\n",
    "else:\n",
    "    print(f\"  ‚úÖ Relatively balanced\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Summary Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"DIAGNOSTIC SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n‚úÖ Checks passed:\")\n",
    "print(\"  - File structure exists\")\n",
    "print(\"  - JSONL format validated\")\n",
    "print(\"  - LMDB integrity confirmed\")\n",
    "print(\"  - Prompts loaded successfully\")\n",
    "\n",
    "if test_only_diseases:\n",
    "    print(f\"\\n‚ùå Critical issues:\")\n",
    "    print(f\"  - {len(test_only_diseases)} diseases in test but not train\")\n",
    "    print(f\"  - These will use generic fallback prompts\")\n",
    "\n",
    "if imbalance_ratio > 100:\n",
    "    print(f\"\\n‚ö†Ô∏è  Warnings:\")\n",
    "    print(f\"  - Severe class imbalance ({imbalance_ratio:.0f}:1)\")\n",
    "    print(f\"  - Consider class weighting in training\")\n",
    "\n",
    "print(f\"\\nüìä Dataset summary:\")\n",
    "print(f\"  Train: {len(train_df)} patients, {len(train_diseases)} with keywords\")\n",
    "print(f\"  Test: {len(test_df)} patients, {len(test_diseases)} with keywords\")\n",
    "print(f\"  Unique diseases (train): {len(train_counts)}\")\n",
    "print(f\"  Unique diseases (test): {len(test_counts)}\")\n",
    "print(f\"  Prompts generated: {len(prompts_df)} patients\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"DIAGNOSTICS COMPLETE\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
